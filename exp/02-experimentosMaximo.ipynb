{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 | Experimentos \"Máximo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "import statistics\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTES\n",
    "ASCII_A = 97\n",
    "ASCII_Z = 122\n",
    "\n",
    "# PARA EXPERIMENTOS\n",
    "\n",
    "# Longitud de palabras\n",
    "WORD_SIZE = 10\n",
    "\n",
    "# Cantidad de palabras\n",
    "START = 500\n",
    "END = 50000\n",
    "STEP = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Generación de instancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_archivo_uniforme(file_name, word_len, words_count):\n",
    "    os.makedirs(F\"../data/\", exist_ok=True)\n",
    "    file_path = \"../data/\" + file_name\n",
    "    file = open(file_path, \"w\")\n",
    "\n",
    "    for i in range(words_count):\n",
    "        word = \"\"\n",
    "        for j in range(word_len): word += chr(randint(ASCII_A, ASCII_Z))\n",
    "        file.write(word + \"\\n\")\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_archivo_normal(file_name, word_len, words_count):\n",
    "    # a b c d e f g h i j k l m <- 13 -> n o p q r s t u v w x y z\n",
    "    MU, SIGMA = 109.5, 8\n",
    "    os.makedirs(F\"../data/\", exist_ok=True)\n",
    "    file_path = \"../data/\" + file_name\n",
    "    file = open(file_path, \"w\")\n",
    "\n",
    "    for i in range(words_count):\n",
    "        word = \"\"\n",
    "        # Muestreamos hasta que obtengamos una palabra de 'word_len' letras, de la 'a' a la 'z' \n",
    "        while len(word) < word_len:\n",
    "            sample = int(np.random.normal(MU, SIGMA))\n",
    "            if ASCII_A <= sample <= ASCII_Z:\n",
    "                word += chr(sample)\n",
    "\n",
    "        file.write(word + \"\\n\")\n",
    "\n",
    "    file.close()\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera las instancias uniforme-START, uniforme-{START+STEP}, ..., uniforme-END y normal-START, normal-{START+STEP}, ..., normal-END\n",
    "for k in range(START, END + 1, STEP):\n",
    "    generar_archivo_uniforme(F\"uniforme-{k}\", WORD_SIZE, k)\n",
    "    generar_archivo_normal(F\"normal-{k}\", WORD_SIZE, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de las muestras\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Uniforme\n",
    "dataset = pd.read_table(\"../data/uniforme-80000\", header=None)\n",
    "letters = [w[0] for w in dataset[0].values.tolist()]\n",
    "letters.sort()\n",
    "letter_count = Counter(letters)\n",
    "df = pd.DataFrame.from_dict(letter_count, orient='index')\n",
    "df.plot(kind='bar')\n",
    "\n",
    "# Normal \n",
    "dataset = pd.read_table(\"../data/normal-80000\", header=None)\n",
    "letters = [w[0] for w in dataset[0].values.tolist()]\n",
    "letters.sort()\n",
    "letter_count = Counter(letters)\n",
    "df = pd.DataFrame.from_dict(letter_count, orient='index')\n",
    "df.plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correr_maximo(archivo_entrada, con_threads=False, cant_threads=0):\n",
    "    algorithm = \"maximoParalelo\" if con_threads else \"maximo\"    \n",
    "    # Crear proceso para ejecutar el codigo.\n",
    "    print(\"Máximo\", archivo_entrada)\n",
    "    process = subprocess.Popen([F\"../build/{algorithm}\", str(cant_threads), os.path.abspath(archivo_entrada)], stderr=subprocess.PIPE, stdout=subprocess.PIPE, stdin=subprocess.PIPE, universal_newlines = True)\n",
    "\n",
    "    # Correr experimento.\n",
    "    exit_code = process.wait()\n",
    "\n",
    "    # Verificar que el proceso no fallo.\n",
    "    if exit_code != 0:\n",
    "        print(exit_code)\n",
    "        print(process.stdout.read())\n",
    "        process.stdout.close()\n",
    "        raise(F\"Hubo un error en la experimentacion: {algorithm} con la instancia {archivo_entrada}.\")\n",
    "    # Leer salida de STDERR con los tiempos de ejecucion de cada metodo.\n",
    "    tiempo_de_ejecucion = float(process.stdout.read())\n",
    "    \n",
    "    process.stdin.close()\n",
    "    process.stdout.close()\n",
    "    process.stderr.close()\n",
    "       \n",
    "    return tiempo_de_ejecucion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento: Tiempos de ejecución para Máximo Paralelo en función de la cantidad de threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERACIONES = 5\n",
    "THREADS = 20\n",
    "COLUMNS = [\"dataset\", \"threads\", \"tiempo\"]\n",
    "entries = []\n",
    "result_dir = \"maximo-tiempos\"\n",
    "datasets = [\"uniforme-10000\", \"normal-10000\", \"uniforme-20000\", \"normal-20000\", \"uniforme-40000\", \"normal-40000\", \"uniforme-80000\", \"normal-80000\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    file = \"../data/\" + dataset\n",
    "    for t in range(1, THREADS + 1):\n",
    "        for i in range(ITERACIONES):\n",
    "            clear_output(wait=True)\n",
    "            display(F\"Ejecutando archivo {file} con cantidad de Threads {t} (Iteración {i}/{ITERACIONES})\")\n",
    "            time = correr_maximo(file, True, t)\n",
    "            entries.append([dataset, t, time])\n",
    "\n",
    "\n",
    "df_resultado = pd.DataFrame(entries, columns=COLUMNS)\n",
    "os.makedirs(F\"results/{result_dir}/\", exist_ok=True)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(F\"Guardando los resultados en el archivo results/{result_dir}/indice.csv\")\n",
    "df_resultado.to_csv(F\"results/{result_dir}/indice.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento: Tiempo de ejecución para una cantidad de threads \"óptima\" vs. utilizar un thread, en función de la cantidad de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERACIONES = 5\n",
    "CANT_THREADS = 8\n",
    "COLUMNS = [\"dataset\", \"funcion\", \"palabras\", \"tiempo\"]\n",
    "entries = []\n",
    "result_dir = \"maximo-single-vs-paralelo\"\n",
    "datasets = [\"uniforme\", \"normal\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for p in range(START, END + 1, STEP):\n",
    "        file = F\"../data/{dataset}-{p}\"\n",
    "        for i in range(ITERACIONES):\n",
    "            # Máximo paralelo\n",
    "            clear_output(wait=True)\n",
    "            display(F\"Ejecutando MÁXIMO PARALELO archivo {file} con cantidad de PALABRAS {p} (Iteración {i}/{ITERACIONES})\")\n",
    "            time = correr_maximo(file, True, CANT_THREADS)\n",
    "            entries.append([dataset, \"maximoParalelo\", p, time])\n",
    "        for i in range(ITERACIONES):\n",
    "            # Máximo sin threading\n",
    "            clear_output(wait=True)\n",
    "            display(F\"Ejecutando MÁXIMO NORMAL archivo {file} con cantidad de PALABRAS {p} (Iteración {i}/{ITERACIONES})\")\n",
    "            time = correr_maximo(file)\n",
    "            entries.append([dataset, \"maximo\", p, time])\n",
    "\n",
    "\n",
    "df_resultado = pd.DataFrame(entries, columns=COLUMNS)\n",
    "os.makedirs(F\"results/{result_dir}/\", exist_ok=True)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(F\"Guardando los resultados en el archivo results/{result_dir}/indice.csv\")\n",
    "df_resultado.to_csv(F\"results/{result_dir}/indice.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
