{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 | Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "import statistics\n",
    "from random import seed\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllFilesAsListOfStrings( dir_path ):\n",
    "    dirPathAsString = dir_path \n",
    "    dir_paths = []\n",
    "    for f in os.listdir(dir_path):\n",
    "        dir_paths.append( dir_path + f )\n",
    "    return dir_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "THREADS = 30\n",
    "result_dir = \"archivos\"\n",
    "cantidadArchivos = 250\n",
    "cantidadPalabrasPorArchivo = 200\n",
    "ITERACIONES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generarArchivoUniforme(nombreArchivo, largoPalabra, cantidadPalabras):\n",
    "    os.makedirs(F\"../data/uniforme/\", exist_ok=True)\n",
    "    pathArchivo = \"../data/uniforme/\" + nombreArchivo\n",
    "    archivo = open(pathArchivo, \"w\")\n",
    "    sal = \"\"\n",
    "    largoPalabra = largoPalabra\n",
    "    for i in range(cantidadPalabras):\n",
    "        for lp in range(largoPalabra):\n",
    "            sal += chr(randint(97, 122))\n",
    "        archivo.write(sal + \"\\n\")\n",
    "        sal = \"\"\n",
    "    return pathArchivo\n",
    "\n",
    "def generarCarpetaUniformes(cantArchivos, cantLetras, cantidadPalabras):\n",
    "    \n",
    "    if not os.path.exists(\"../data/uniforme/\"):\n",
    "        os.makedirs(\"../data/uniforme/\")\n",
    "\n",
    "    #borramos los archivos viejos para generar los nuevos\n",
    "    for f in os.listdir(\"../data/uniforme/\"):\n",
    "        os.remove(\"../data/uniforme/\"+ str(f) )\n",
    "\n",
    "    fileName = \"uniforme\"\n",
    "    for i in range(cantArchivos):\n",
    "        nombre = fileName + str(i)\n",
    "        generarArchivoUniforme(nombre, cantLetras, cantidadPalabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generarArchivoNormal(nombreArchivo, largoPalabra, cantidadPalabras, _sigma):\n",
    "    # a b c d e f g h i j k l m 13 n o p q r s t u v w x y z\n",
    "    mu= 109.5 #normal( 109.5, 3 ) \n",
    "    sigma = _sigma\n",
    "    #con estos valores, la probabilidad de generar un valor fuera del rago de los caracteres ascii es demasiado baja.\n",
    "    #de todas formas si se generara alguno, lo descartamos antes de convertirlo a char\n",
    "    os.makedirs(F\"../data/normal/\", exist_ok=True)\n",
    "    pathArchivo = \"../data/normal/\" + nombreArchivo\n",
    "    archivo = open(pathArchivo, \"w\")\n",
    "    sal = \"\"\n",
    "    largoPalabra = largoPalabra\n",
    "    for i in range(cantidadPalabras):\n",
    "        for lp in range(largoPalabra):\n",
    "            val = int(np.random.normal()*sigma + mu)\n",
    "            if val >=97 and val <= 122:\n",
    "                sal += chr(val)\n",
    "        archivo.write(sal + \"\\n\")\n",
    "        sal = \"\"\n",
    "    archivo.close()\n",
    "    return pathArchivo\n",
    "\n",
    "def generarCarpetaNormal(cantArchivos, cantLetras, cantidadPalabras, sigma):\n",
    "    fileName = \"normal\"\n",
    "    #si no existe la carpeta la creamos\n",
    "    if not os.path.exists(\"../data/normal/\"):\n",
    "        os.makedirs(\"../data/normal/\")\n",
    "        \n",
    "    #borramos los archivos viejos para generar los nuevos\n",
    "    for f in os.listdir(\"../data/normal/\"):\n",
    "        os.remove(\"../data/normal/\"+ str(f) )\n",
    "\n",
    "    for i in range(cantArchivos):\n",
    "        nombre = fileName + str(i)\n",
    "        generarArchivoNormal(nombre, cantLetras, cantidadPalabras, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correr_experimento(funcion, cant_threads, archivos_entradas):\n",
    "    # Crear proceso para ejecutar el codigo.\n",
    "    taskAndParameters = [ \"../build/archivos\", cant_threads, str(len(archivos_entradas))]\n",
    "    \n",
    "    for f in archivos_entradas:\n",
    "        taskAndParameters.append( os.path.abspath(f) )\n",
    "\n",
    "    process = subprocess.Popen(taskAndParameters, stderr=subprocess.PIPE, stdout=subprocess.PIPE, universal_newlines = True)\n",
    "\n",
    "    # Correr experimento.\n",
    "    exit_code = process.wait()\n",
    "\n",
    "    # Verificar que el proceso no fallo.\n",
    "    if exit_code != 0:\n",
    "        print(exit_code)\n",
    "        print(process.stderr.read())\n",
    "        process.stderr.close()\n",
    "        raise(F\"Hubo un error en la experimentacion: {funcion} con la instancia {archivo_entrada}.\")\n",
    "    # Leer salida de STDERR con los tiempos de ejecucion de cada metodo.\n",
    "    # [cant threads , cantidad archivos, tiempo promedio, maximoasignado, minimo asignado, media restante]\n",
    "    resultado = process.stdout.readline()\n",
    "    process.stdout.close()\n",
    "    process.stderr.close()\n",
    "       \n",
    "    return resultado.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suma(s,t):\n",
    "    res = [0.0]*len(s)\n",
    "    for i in range( len(s) ):\n",
    "        res [i] = float(s[i]) + float(t[i])\n",
    "    return res\n",
    "def promedio(s, repe):\n",
    "    res = [0.0]*len(s)\n",
    "    for i in range(len(s)):\n",
    "        res[i] = s[i] / int(repe)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ejecutando carpetas uniforme con cantidad de Threads 30 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Guardando los resultados en el archivo results/archivos/uniforme.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_paths = \"../data/uniforme/\"\n",
    "entries = []\n",
    "carpeta = \"uniforme\"\n",
    "\n",
    "generarCarpetaUniformes( cantidadArchivos, 6, cantidadPalabrasPorArchivo )\n",
    "\n",
    "file_paths = getAllFilesAsListOfStrings(dir_paths)\n",
    "\n",
    "for t in range( 1, THREADS+1 ):\n",
    "    clear_output(wait=True)\n",
    "    display(F\"Ejecutando carpetas {carpeta} con cantidad de Threads {t} \" )\n",
    "    salida_temp = [0.0]*5\n",
    "    for i in range (ITERACIONES):\n",
    "        salida = correr_experimento(\"archivos\", str(t), file_paths )\n",
    "        salida_temp = suma( salida_temp, salida )\n",
    "    salida_temp = promedio(salida_temp, ITERACIONES)\n",
    "    entries.append(salida_temp)\n",
    "\n",
    "df_resultado = pd.DataFrame(entries, columns=[\"cantThreads\", \"cantArchivos\", \"tiempoTotal\", \"tiempoMedio\", \"medLoad\"])\n",
    "os.makedirs(F\"results/{result_dir}/\", exist_ok=True)\n",
    "\n",
    "display(F\"Guardando los resultados en el archivo results/{result_dir}/uniforme.csv\")\n",
    "df_resultado.to_csv(F\"results/{result_dir}/uniforme.csv\", index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guardando los resultados en el archivo results/archivos/normalsigma3.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_paths = \"../data/normal/\"\n",
    "entries = []\n",
    "carpeta = \"normal\"\n",
    "\n",
    "generarCarpetaNormal(cantidadArchivos, 6, cantidadPalabrasPorArchivo, 3)\n",
    "\n",
    "file_paths = getAllFilesAsListOfStrings(dir_paths)\n",
    "\n",
    "for t in range( 1, THREADS+1 ):\n",
    "    clear_output(wait=True)\n",
    "    display(F\"Ejecutando carpetas {carpeta} con cantidad de Threads {t} \" )\n",
    "    salida_temp = [0.0]*5\n",
    "    for i in range(ITERACIONES):\n",
    "        salida = correr_experimento(\"CargarArchivos\", str(t), file_paths)\n",
    "        salida_temp = suma(salida_temp, salida)\n",
    "    salida_temp = promedio(salida_temp, ITERACIONES)\n",
    "    entries.append(salida_temp)\n",
    "\n",
    "df_resultado = pd.DataFrame(entries, columns=[\"cantThreads\", \"cantArchivos\", \"tiempoTotal\", \"tiempoMedio\", \"medLoad\"])\n",
    "os.makedirs(F\"results/{result_dir}/\", exist_ok=True)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(F\"Guardando los resultados en el archivo results/{result_dir}/normalsigma3.csv\")\n",
    "df_resultado.to_csv(F\"results/{result_dir}/normalsigma3.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guardando los resultados en el archivo results/archivos/sigma8variandocantPalabras.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigmas = [\"0.125\", \"0.25\", \"0.5\", \"1\", \"2\", \"3\", \"4\", \"8\"]\n",
    "entries = []\n",
    "\n",
    "dir_normal = \"../data/normal/\"\n",
    "\n",
    "for sigma in sigmas:\n",
    "    entries = []\n",
    "    for i in range(100, 1001, 100):\n",
    "        generarCarpetaNormal( 100, 10, i, float(sigma) )\n",
    "        file_paths = getAllFilesAsListOfStrings(dir_normal)\n",
    "        clear_output(wait=True)\n",
    "        salida_temp = [0.0]*5\n",
    "        for j in range(3):\n",
    "            salida = correr_experimento(\"CargarArchivos\", str(4), file_paths)\n",
    "            salida_temp = suma(salida_temp, salida)\n",
    "        salida_temp = promedio(salida_temp, ITERACIONES)\n",
    "        salida_temp.append(i)\n",
    "        entries.append(salida_temp)\n",
    "        df_resultado = pd.DataFrame(entries, columns=[\"cantThreads\", \"cantArchivos\", \"tiempoTotal\",\"tiempoMedio\", \"medLoad\", \"cantPalabras\"])\n",
    "        os.makedirs( F\"results/{result_dir}/\", exist_ok=True )\n",
    "    clear_output(wait=True)\n",
    "    display(F\"Guardando los resultados en el archivo results/{result_dir}/sigma{sigma}variandocantPalabras.csv\")\n",
    "    df_resultado.to_csv(F\"results/{result_dir}/sigma{sigma}variandocantPalabras.csv\", index=False, header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sigma = 0.125'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "5 columns passed, passed data had 6 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:934\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 934\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    935\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    936\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:981\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_mi_list \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(columns) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(content):  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    980\u001b[0m     \u001b[39m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    982\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(columns)\u001b[39m}\u001b[39;00m\u001b[39m columns passed, passed data had \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    983\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(content)\u001b[39m}\u001b[39;00m\u001b[39m columns\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    984\u001b[0m     )\n\u001b[1;32m    985\u001b[0m \u001b[39mif\u001b[39;00m is_mi_list:\n\u001b[1;32m    986\u001b[0m     \u001b[39m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 5 columns passed, passed data had 6 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     salida_temp\u001b[39m.\u001b[39mappend(i)\n\u001b[1;32m     18\u001b[0m     entries\u001b[39m.\u001b[39mappend(salida_temp)\n\u001b[0;32m---> 19\u001b[0m     df_resultado \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(entries, columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcantThreads\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcantArchivos\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtiempoMedio\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmedLoad\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msigma\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     20\u001b[0m     os\u001b[39m.\u001b[39mmakedirs( \u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mresults/\u001b[39m\u001b[39m{\u001b[39;00mresult_dir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m )\n\u001b[1;32m     22\u001b[0m clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 782\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    783\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    784\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    785\u001b[0m         data,\n\u001b[1;32m    786\u001b[0m         columns,\n\u001b[1;32m    787\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    788\u001b[0m         dtype,\n\u001b[1;32m    789\u001b[0m     )\n\u001b[1;32m    790\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    791\u001b[0m         arrays,\n\u001b[1;32m    792\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    795\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    796\u001b[0m     )\n\u001b[1;32m    797\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:498\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[0;32m--> 498\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    499\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    501\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:840\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    837\u001b[0m     data \u001b[39m=\u001b[39m [\u001b[39mtuple\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[1;32m    838\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 840\u001b[0m content, columns \u001b[39m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[1;32m    841\u001b[0m \u001b[39mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:937\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    934\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    935\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    936\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(contents) \u001b[39mand\u001b[39;00m contents[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mobject_:\n\u001b[1;32m    940\u001b[0m     contents \u001b[39m=\u001b[39m convert_object_array(contents, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 5 columns passed, passed data had 6 columns"
     ]
    }
   ],
   "source": [
    "#sigmas = [\"0.125\",\"0.25\", \"0.375\", \"0.5\",\"0.75\",\"0.875\", \"1\", \"1.25\", \"1.5\", \"1.75\", \"2\",\"2.25\", \"2.5\",\"2.75\", \"3\",\"3.25\", \"3.5\", \"4\", \"4.5\", \"5\", \"6\", \"7\", \"8\"]\n",
    "sigmas = [\"0.125\", \"0.25\", \"0.5\", \"1\", \"2\", \"3\", \"4\", \"8\"]\n",
    "entries = []\n",
    "\n",
    "dir_normal = \"../data/normal/\"\n",
    "\n",
    "for i in sigmas:\n",
    "    generarCarpetaNormal(cantidadArchivos, 10, cantidadPalabrasPorArchivo, float(i) )\n",
    "    file_paths = getAllFilesAsListOfStrings(dir_normal)\n",
    "    clear_output(wait=True)\n",
    "    display( F\"Sigma = {i}\" )\n",
    "    salida_temp = [0.0]*5\n",
    "    for j in range(ITERACIONES):\n",
    "        salida = correr_experimento(\"CargarArchivos\", str(4), file_paths)\n",
    "        salida_temp = suma(salida_temp, salida)\n",
    "    salida_temp = promedio(salida_temp, ITERACIONES)\n",
    "    salida_temp.append(i)\n",
    "    entries.append(salida_temp)\n",
    "    df_resultado = pd.DataFrame(entries, columns=[\"cantThreads\", \"cantArchivos\", \"tiempoTotal\", \"tiempoMedio\", \"medLoad\", \"sigma\"])\n",
    "    os.makedirs( F\"results/{result_dir}/\", exist_ok=True )\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(F\"Guardando los resultados en el archivo results/{result_dir}/sigma.csv\")\n",
    "df_resultado.to_csv(F\"results/{result_dir}/sigma.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
