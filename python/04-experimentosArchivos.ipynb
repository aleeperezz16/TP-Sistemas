{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 | Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "from random import seed\n",
    "from random import randint\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllFilesAsListOfStrings( dir_path ):\n",
    "    dirPathAsString = dir_path \n",
    "    dir_paths = []\n",
    "    for f in os.listdir(dir_path):\n",
    "        dir_paths.append( dir_path + f )\n",
    "    return dir_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "THREADS = multiprocessing.cpu_count()\n",
    "result_dir = \"archivos\"\n",
    "cantidadArchivos = 500\n",
    "cantidadPalabrasPorArchivo = 700\n",
    "ITERACIONES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generarArchivoUniforme(nombreArchivo, largoPalabra, cantidadPalabras):\n",
    "    os.makedirs(F\"../data/uniforme/\", exist_ok=True)\n",
    "    pathArchivo = \"../data/uniforme/\" + nombreArchivo\n",
    "    archivo = open(pathArchivo, \"w\")\n",
    "    sal = \"\"\n",
    "    largoPalabra = largoPalabra\n",
    "    for i in range(cantidadPalabras):\n",
    "        for lp in range(largoPalabra):\n",
    "            sal += chr(randint(97, 122))\n",
    "        archivo.write(sal + \"\\n\")\n",
    "        sal = \"\"\n",
    "    return pathArchivo\n",
    "\n",
    "def generarCarpetaUniformes(cantArchivos, cantLetras, cantidadPalabras):\n",
    "    \n",
    "    if not os.path.exists(\"../data/uniforme/\"):\n",
    "        os.makedirs(\"../data/uniforme/\")\n",
    "\n",
    "    #borramos los archivos viejos para generar los nuevos\n",
    "    for f in os.listdir(\"../data/uniforme/\"):\n",
    "        os.remove(\"../data/uniforme/\"+ str(f) )\n",
    "\n",
    "    fileName = \"uniforme\"\n",
    "    for i in range(cantArchivos):\n",
    "        nombre = fileName + str(i)\n",
    "        generarArchivoUniforme(nombre, cantLetras, cantidadPalabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generarArchivoNormal(nombreArchivo, largoPalabra, cantidadPalabras, _sigma):\n",
    "    # a b c d e f g h i j k l m 13 n o p q r s t u v w x y z\n",
    "    mu= 109.5 #normal( 109.5, 3 ) \n",
    "    sigma = _sigma\n",
    "    #con estos valores, la probabilidad de generar un valor fuera del rago de los caracteres ascii es demasiado baja.\n",
    "    #de todas formas si se generara alguno, lo descartamos antes de convertirlo a char\n",
    "    os.makedirs(F\"../data/normal/\", exist_ok=True)\n",
    "    pathArchivo = \"../data/normal/\" + nombreArchivo\n",
    "    archivo = open(pathArchivo, \"w\")\n",
    "    sal = \"\"\n",
    "    largoPalabra = largoPalabra\n",
    "    for i in range(cantidadPalabras):\n",
    "        for lp in range(largoPalabra):\n",
    "            val = int(np.random.normal()*sigma + mu)\n",
    "            if val >=97 and val <= 122:\n",
    "                sal += chr(val)\n",
    "        archivo.write(sal + \"\\n\")\n",
    "        sal = \"\"\n",
    "    archivo.close()\n",
    "    return pathArchivo\n",
    "\n",
    "def generarCarpetaNormal(cantArchivos, cantLetras, cantidadPalabras, sigma):\n",
    "    fileName = \"normal\"\n",
    "    #si no existe la carpeta la creamos\n",
    "    if not os.path.exists(\"../data/normal/\"):\n",
    "        os.makedirs(\"../data/normal/\")\n",
    "        \n",
    "    #borramos los archivos viejos para generar los nuevos\n",
    "    for f in os.listdir(\"../data/normal/\"):\n",
    "        os.remove(\"../data/normal/\"+ str(f) )\n",
    "\n",
    "    for i in range(cantArchivos):\n",
    "        nombre = fileName + str(i)\n",
    "        generarArchivoNormal(nombre, cantLetras, cantidadPalabras, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correr_experimento(funcion, cant_threads, archivos_entradas):\n",
    "    # Crear proceso para ejecutar el codigo.\n",
    "    taskAndParameters = [ \"../build/archivos\", cant_threads, str(len(archivos_entradas))]\n",
    "    \n",
    "    for f in archivos_entradas:\n",
    "        taskAndParameters.append( os.path.abspath(f) )\n",
    "\n",
    "    process = subprocess.Popen(taskAndParameters, stderr=subprocess.PIPE, stdout=subprocess.PIPE, universal_newlines = True)\n",
    "\n",
    "    # Correr experimento.\n",
    "    exit_code = process.wait()\n",
    "\n",
    "    # Verificar que el proceso no fallo.\n",
    "    if exit_code != 0:\n",
    "        print(exit_code)\n",
    "        print(process.stderr.read())\n",
    "        process.stderr.close()\n",
    "        raise(F\"Hubo un error en la experimentacion: {funcion} con la instancia {archivos_entradas}.\")\n",
    "    # Leer salida de STDERR con los tiempos de ejecucion de cada metodo.\n",
    "    # [cant threads , cantidad archivos, tiempo promedio, maximoasignado, minimo asignado, media restante]\n",
    "    resultado = process.stdout.readline()\n",
    "    process.stdout.close()\n",
    "    process.stderr.close()\n",
    "       \n",
    "    return resultado.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suma(s,t):\n",
    "    res = [0.0]*len(s)\n",
    "    for i in range( len(s) ):\n",
    "        res [i] = float(s[i]) + float(t[i])\n",
    "    return res\n",
    "def promedio(s, repe):\n",
    "    res = [0.0]*len(s)\n",
    "    for i in range(len(s)):\n",
    "        res[i] = s[i] / int(repe)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ejecutando carpetas uniforme con cantidad de Threads 8 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Guardando los resultados en el archivo results/archivos/uniforme.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_paths = \"../data/uniforme/\"\n",
    "entries = []\n",
    "carpeta = \"uniforme\"\n",
    "\n",
    "generarCarpetaUniformes( cantidadArchivos, 6, cantidadPalabrasPorArchivo )\n",
    "\n",
    "file_paths = getAllFilesAsListOfStrings(dir_paths)\n",
    "\n",
    "for t in range( 1, THREADS+1 ):\n",
    "    clear_output(wait=True)\n",
    "    display(F\"Ejecutando carpetas {carpeta} con cantidad de Threads {t} \" )\n",
    "    salida_temp = [0.0]*5\n",
    "    for i in range (ITERACIONES):\n",
    "        salida = correr_experimento(\"archivos\", str(t), file_paths )\n",
    "        salida_temp = suma( salida_temp, salida )\n",
    "    salida_temp = promedio(salida_temp, ITERACIONES)\n",
    "    entries.append(salida_temp)\n",
    "\n",
    "df_resultado = pd.DataFrame(entries, columns=[\"cantThreads\", \"cantArchivos\", \"tiempoTotal\", \"tiempoMedio\", \"medLoad\"])\n",
    "os.makedirs(F\"results/{result_dir}/\", exist_ok=True)\n",
    "\n",
    "display(F\"Guardando los resultados en el archivo results/{result_dir}/uniforme.csv\")\n",
    "df_resultado.to_csv(F\"results/{result_dir}/uniforme.csv\", index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guardando los resultados en el archivo results/archivos/normalsigma3.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_paths = \"../data/normal/\"\n",
    "entries = []\n",
    "carpeta = \"normal\"\n",
    "\n",
    "generarCarpetaNormal(cantidadArchivos, 6, cantidadPalabrasPorArchivo, 3)\n",
    "\n",
    "file_paths = getAllFilesAsListOfStrings(dir_paths)\n",
    "\n",
    "for t in range( 1, THREADS+1 ):\n",
    "    clear_output(wait=True)\n",
    "    display(F\"Ejecutando carpetas {carpeta} con cantidad de Threads {t} \" )\n",
    "    salida_temp = [0.0]*5\n",
    "    for i in range(ITERACIONES):\n",
    "        salida = correr_experimento(\"CargarArchivos\", str(t), file_paths)\n",
    "        salida_temp = suma(salida_temp, salida)\n",
    "    salida_temp = promedio(salida_temp, ITERACIONES)\n",
    "    entries.append(salida_temp)\n",
    "\n",
    "df_resultado = pd.DataFrame(entries, columns=[\"cantThreads\", \"cantArchivos\", \"tiempoTotal\", \"tiempoMedio\", \"medLoad\"])\n",
    "os.makedirs(F\"results/{result_dir}/\", exist_ok=True)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(F\"Guardando los resultados en el archivo results/{result_dir}/normalsigma3.csv\")\n",
    "df_resultado.to_csv(F\"results/{result_dir}/normalsigma3.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guardando los resultados en el archivo results/archivos/sigma8variandocantPalabras.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigmas = [\"0.125\", \"0.25\", \"0.5\", \"1\", \"2\", \"3\", \"4\", \"8\"]\n",
    "entries = []\n",
    "\n",
    "dir_normal = \"../data/normal/\"\n",
    "\n",
    "for sigma in sigmas:\n",
    "    entries = []\n",
    "    for i in range(100, 1001, 100):\n",
    "        generarCarpetaNormal( cantidadArchivos, 10, i, float(sigma) ) #i: cantidad de palabras por letras [ 100, 200 ... 1000 ]\n",
    "        file_paths = getAllFilesAsListOfStrings(dir_normal)\n",
    "        clear_output(wait=True)\n",
    "        salida_temp = [0.0]*5\n",
    "        for j in range(3):\n",
    "            salida = correr_experimento(\"CargarArchivos\", str(4), file_paths)\n",
    "            salida_temp = suma(salida_temp, salida)\n",
    "        salida_temp = promedio(salida_temp, ITERACIONES)\n",
    "        salida_temp.append(i)\n",
    "        entries.append(salida_temp)\n",
    "        df_resultado = pd.DataFrame(entries, columns=[\"cantThreads\", \"cantArchivos\", \"tiempoTotal\",\"tiempoMedio\", \"medLoad\", \"cantPalabras\"])\n",
    "        os.makedirs( F\"results/{result_dir}/\", exist_ok=True )\n",
    "    clear_output(wait=True)\n",
    "    display(F\"Guardando los resultados en el archivo results/{result_dir}/sigma{sigma}variandocantPalabras.csv\")\n",
    "    df_resultado.to_csv(F\"results/{result_dir}/sigma{sigma}variandocantPalabras.csv\", index=False, header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guardando los resultados en el archivo results/archivos/sigma.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sigmas = [\"0.125\",\"0.25\", \"0.375\", \"0.5\",\"0.75\",\"0.875\", \"1\", \"1.25\", \"1.5\", \"1.75\", \"2\",\"2.25\", \"2.5\",\"2.75\", \"3\",\"3.25\", \"3.5\", \"4\", \"4.5\", \"5\", \"6\", \"7\", \"8\"]\n",
    "sigmas = [\"0.125\", \"0.25\", \"0.375\", \"0.5\",\"0.75\" ,\"1\", \"2\", \"3\", \"4\", \"8\"]\n",
    "entries = []\n",
    "\n",
    "dir_normal = \"../data/normal/\"\n",
    "\n",
    "for i in sigmas:\n",
    "    generarCarpetaNormal(cantidadArchivos, 10, cantidadPalabrasPorArchivo, float(i) )\n",
    "    file_paths = getAllFilesAsListOfStrings(dir_normal)\n",
    "    clear_output(wait=True)\n",
    "    display( F\"Sigma = {i}\" )\n",
    "    salida_temp = [0.0]*5\n",
    "    for j in range(ITERACIONES):\n",
    "        salida = correr_experimento(\"CargarArchivos\", str(4), file_paths)\n",
    "        salida_temp = suma(salida_temp, salida)\n",
    "    salida_temp = promedio(salida_temp, ITERACIONES)\n",
    "    salida_temp.append(i)\n",
    "    entries.append(salida_temp)\n",
    "    df_resultado = pd.DataFrame(entries, columns=[\"cantThreads\", \"cantArchivos\", \"tiempoTotal\", \"tiempoMedio\", \"medLoad\", \"sigma\"])\n",
    "    os.makedirs( F\"results/{result_dir}/\", exist_ok=True )\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(F\"Guardando los resultados en el archivo results/{result_dir}/sigma.csv\")\n",
    "df_resultado.to_csv(F\"results/{result_dir}/sigma.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
